# "Dev 환경 오토스케일링 - 부하에 따라 Pod 수 자동 조절"

# HPA란?
# - 부하(CPU, Memory)에 따라 Pod 수 자동 조절
# - 트래픽 증가 → Pod 증가 (Scale Out)
# - 트래픽 감소 → Pod 감소 (Scale In)
apiVersion: autoscaling/v2 # autoscaling/v2 API (v2beta1 제거됨)
kind: HorizontalPodAutoscaler
metadata:
  name: app-hpa
spec:
  # ---------------------------------------------------------------------------
  # scaleTargetRef: HPA가 제어할 대상
  # ---------------------------------------------------------------------------
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: app # base/deployment.yaml의 name과 일치

  # ---------------------------------------------------------------------------
  # 스케일링 범위
  # ---------------------------------------------------------------------------
  minReplicas: 1 # 최소 1개 (Dev는 비용 절감)
  maxReplicas: 3 # 최대 3개 (Dev는 제한적)

  # ---------------------------------------------------------------------------
  # metrics: 스케일링 기준
  # ---------------------------------------------------------------------------
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          # CPU 사용률 80% 초과 시 스케일 아웃
          # Dev는 여유있게 설정 (테스트 목적)
          averageUtilization: 80

  # ---------------------------------------------------------------------------
  # behavior: 스케일링 동작 미세 조정
  # ---------------------------------------------------------------------------
  behavior:
    scaleDown:
      # 축소 전 대기 시간: 60초
      # Dev는 빠르게 축소 (비용 절약)
      # Prod는 300초로 설정 (안정성)
      stabilizationWindowSeconds: 60

# HPA가 CPU 사용률을 감지하는 과정은 마법처럼 일어나는 것이 아니라,
# **cAdvisor → Kubelet → Metrics Server → HPA Controller**로 이어지는 명확한 데이터 수집 파이프라인을 통해 이루어집니다.
# 가장 중요한 핵심 컴포넌트는 Metrics Server입니다.
# CPU 감지 및 처리 전체 흐름 (4단계)쿠버네티스 내부에서 다음과 같은 순서로 데이터를 주고받습니다.
# 1. 측정 (cAdvisor)각 노드(Node)에는 Kubelet이라는 에이전트가 실행 중입니다.
# Kubelet 내부에는 cAdvisor(Container Advisor)라는 도구 포함되어 있는데,
# 이 녀석이 실시간으로 각 컨테이너(Pod)가 CPU와 메모리를 얼마나 쓰고 있는지 Raw 데이터(나노코어 단위)를 수집합니다.
# 2. 수집 (Metrics Server)클러스터에는 Metrics Server라는 별도의 Pod가 떠 있어야 합니다.
# (EKS 등 관리형 서비스는 보통 기본 설치 혹은 애드온으로 설치됨)
# Metrics Server는 주기적으로(기본 60초 등) 모든 노드의 Kubelet에 접속해서 "지금 Pod들이 자원 얼마나 써?"라고 물어보고
# 데이터를 긁어와서(Scraping) 메모리에 저장합니다.
# 3. 조회 HPA Controller(쿠버네티스 컨트롤 플레인에 존재)는 기본적으로 15초마다 루프를 돌며 체크합니다.
# Metrics Server에게 "app-hpa가 감시하는 Pod들의 현재 평균 CPU 사용률이 얼마야?"라고 API를 통해 조회합니다.
# 4. 계산 및 조정 (Scaling) HPA는 받아온 현재 사용률과 사용자가 YAML에 정의한 목표 사용률(80%)을 비교합니다.
# 계산 결과에 따라 Pod 개수(Replicas)를 늘리거나(Scale Out) 줄이라고(Scale In) Deployment에 명령을 내립니다.
# 💡 핵심 포인트: "80%"의 기준은 무엇인가?
# 많은 분들이 헷갈려 하는 부분입니다.
# YAML에 적힌 averageUtilization: 80은 Node 전체 CPU의 80%가 아닙니다.
# 바로 Pod에 설정된 requests(요청량) 대비 80%입니다.
# 예시 상황:Pod 설정: resources.requests.cpu: 100m (0.1코어) HPA 설정: averageUtilization: 80
# (80% 넘으면 늘려라)작동:
# Pod가 50m 사용 중 → 50% 사용 (동작 안 함)
# Pod가 90m 사용 중 → 90% 사용 (80% 초과했으므로 Pod 추가 생성)⚠
# ️ 주의사항 (실무 팁) Metrics Server 필수: kubectl top pod 명령어가 안 먹히면 Metrics Server가 없는 것입니다.
# HPA도 작동하지 않습니다.
# Requests 설정 필수: Deployment YAML에 resources.requests.cpu가 없으면, HPA는 기준 분모(Request)를 알 수 없어서 동작하지 않습니다.
