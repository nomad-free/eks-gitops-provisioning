name: Deploy to Prod

on:
  workflow_run:
    workflows: ["CI"]
    types:
      - completed
    branches:
      - main

permissions:
  id-token: write
  contents: read
  packages: write

env:
  AWS_REGION: ${{ vars.AWS_REGION }}
  ECR_REPOSITORY: ${{ vars.ECR_REPOSITORY }}
  EKS_CLUSTER_NAME: ${{ vars.EKS_CLUSTER_NAME }}
  ENVIRONMENT: prod

jobs:
  # Job 1: security-scan - Prod ì „ìš© ë³´ì•ˆ ìŠ¤ìº”
  security-scan:
    name: ğŸ”’ Security Scan
    runs-on: ubuntu-latest
    if: ${{ github.event.workflow_run.conclusion == 'success' }}

    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ğŸ” Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@0.29.0
        with:
          scan-type: "fs"
          scan-ref: "."
          severity: "CRITICAL,HIGH"
          exit-code: "1" # â­ ì·¨ì•½ì  ë°œê²¬ ì‹œ ë¹Œë“œ ì‹¤íŒ¨!
  # Job 2: build - Docker ë¹Œë“œ & ECR Push
  build:
    name: ğŸ—ï¸ Build & Push
    runs-on: ubuntu-latest
    needs: security-scan
    environment: prod
    outputs:
      image_uri: ${{ steps.set-output.outputs.image_uri }}
      image_tag: ${{ steps.meta.outputs.version }}

    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ğŸ” Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          role-session-name: gha-prod-${{ github.run_id }}
          aws-region: ${{ env.AWS_REGION }}

      - name: ğŸ” Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2
      # Prod ì´ë¯¸ì§€ íƒœê·¸ ìƒì„±: v1.0.0-abc1234
      - name: ğŸ“‹ Generate Metadata
        id: meta
        run: |
          VERSION=$(cat VERSION 2>/dev/null || echo "1.0.0")
          SHORT_SHA=$(echo ${{ github.sha }} | cut -c1-7)
          echo "version=v${VERSION}-${SHORT_SHA}" >> $GITHUB_OUTPUT

      - name: ğŸ”§ Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: ğŸ³ Build and push Docker image
        id: build
        uses: docker/build-push-action@v6
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        with:
          context: ./app
          push: true
          tags: |
            ${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPOSITORY }}:${{ steps.meta.outputs.version }}
            ${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPOSITORY }}:latest-prod
          cache-from: type=gha
          cache-to: type=gha,mode=max
          provenance: true # â­ Provenance ì •ë³´ (ë¹Œë“œ ì¶œì²˜ ì¦ëª…)
          sbom: true # â­ SBOM ìƒì„± (ì†Œí”„íŠ¸ì›¨ì–´ êµ¬ì„± ëª©ë¡)

      - name: ğŸ“¤ Set Job Output
        id: set-output
        run: |
          echo "image_uri=${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPOSITORY }}:${{ steps.meta.outputs.version }}" >> $GITHUB_OUTPUT
  # Job 3: deploy - EKS ë°°í¬ + ìë™ ë¡¤ë°±
  deploy:
    name: ğŸš€ Deploy to Prod
    runs-on: ubuntu-latest
    needs: build
    environment: prod

    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ğŸ” Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: ğŸ”§ Setup kubectl
        uses: azure/setup-kubectl@v4
        with:
          version: "latest"

      - name: ğŸ”— Configure kubectl
        run: |
          aws eks update-kubeconfig \
            --region ${{ env.AWS_REGION }} \
            --name ${{ env.EKS_CLUSTER_NAME }}
      - name: ğŸš€ Deploy
        id: deploy
        run: |
          cd kustomize/overlays/prod

          # ì´ë¯¸ì§€ íƒœê·¸ ì—…ë°ì´íŠ¸
          kustomize edit set image app=${{ needs.build.outputs.image_uri }}

          # ë°°í¬ (SAëŠ” ì´ë¯¸ Terraformì—ì„œ ìƒì„±ë¨)
          kubectl apply -k .
      # =========================================================================
      - name: â³ Wait for rollout
        id: rollout
        run: |
          if kubectl rollout status deployment/app -n app-prod --timeout=300s; then
            echo "status=success" >> $GITHUB_OUTPUT
          else
            echo "status=failed" >> $GITHUB_OUTPUT
            exit 1
          fi

      - name: âª Auto Rollback
        if: failure() && steps.rollout.outputs.status == 'failed'
        run: |
          echo "ğŸš¨ Deployment Failed! Initiating Rollback..."
          kubectl rollout undo deployment/app -n app-prod
          if kubectl rollout status deployment/app -n app-prod --timeout=300s; then
            echo "âœ… Rollback Successful."
          else
            echo "âŒ Rollback Failed. Manual intervention required!"
          fi
